---
title: "Stats. Inference Assignment 3"
author: "Naeem Chowdhury"
date: "5/19/2020"
output: pdf_document
---


##1. Setup
### options
Set up global options
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy=TRUE)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=70))
knitr::opts_chunk$set(fig.height=4, fig.width=6)
```

### libraries
Load in needed libraries 
```{r}
library(tidyverse)
library(RColorBrewer)
library(haven)
```

## 2. File management
### Create variables for directories
```{r file_management}
project.dir <- getwd() #naeem
output.dir <- "/Output"
data.dir <- "C:/Users/Naeem Cho/Desktop/School Work/Statistical Inference/Datasets"
setwd(project.dir)
getwd()
```

## 3. Importing Data
```{r}
cpu.data <- read_csv(file.path(data.dir, "Intel_CPUs.csv"))
```

# Problem #1

## 1. Code up your own _my.chisq.test()_ function that will perform a $\chi^2$ test. As a single argument, it should just take a contingency table of arbitrary size. As output, it should provide:

- Calculated $\chi^2$ statistic
- $p$-value

Caclulating the expected cell counts under $H_0$ hypothesis should constitute a critical part of your function definition. Don't use neither _chisq.test()_ nor _prop.test()_, nor any other "fancy cheat" built-in functions inside your function's definition.

```{r}
data <- matrix(c(18, 20, 15, 15, 10, 55, 65, 70, 30), nrow=3)

my.chisq.test <- function(ctable) {
  rows <- nrow(ctable)
  cols <- ncol(ctable)
  
  rowsums <- rowSums(ctable)
  colsums <-colSums(ctable)
  
  total <- sum(ctable)
  df <- (rows-1)*(cols-1)
  
  expected <- matrix(0, nrow = rows, ncol = cols)
  
  for(i in 1:rows){
    
    for(j in 1:cols){
      
      expected[i,j] <- (rowsums[i]*colsums[j])/ total
      
    }
  }
  chi_sq <- ((ctable - expected)^2)/expected
  chi_sq <- sum(chi_sq)
  
  p <- pchisq(chi_sq, df, lower.tail = FALSE)
  
  
  print(c("X-Squared: ",  chi_sq))
  print(c("Degrees of Freedom: ", df))
  print(c("p-value: ", p))
  # print(c("Matrix of expected counts: ", expected))
}
```

## 2. Testing on a CPU/GPU Dataset


### a. What variables are we interested in?

```{r}
vert_stat <- cpu.data %>% select(Vertical_Segment, Status) %>% drop_na()
table(vert_stat)
```
I've selected two categorical variables from the Intel_CPUs dataset which each have 4 categories. However, since the 'Announced' category and 'Embedded' category have very few variables, I've decided to drop them in order to simplify the analysis.

```{r}
vert_stat <- cpu.data %>% select(Vertical_Segment, Status) %>% filter(Vertical_Segment != 'Embedded' & Status != 'Announced') %>%  drop_na()
ctable <- table(vert_stat)
```

### b. What are the hypotheses?

$H_0$ := The launch Status of a CPU is independent of its Vertical_Segment type.

$H_a$ := The launch status of an Intel CPU is dependent on its Vertical Segment type.

### c. Print the contingency table. Under $H_0$ hypothesis, proceed to calculate expected counts for two arbitrary cells of the contingency table.

```{r}
ctable

# Calculating the expected counts for two arbitrary cells.
rows <- nrow(ctable)
cols <- ncol(ctable)
rowsums <- rowSums(ctable)
colsums <-colSums(ctable)
total <- sum(ctable)

# Produce the pairs of row and column location of arbitrary position
r.indices <- sample(1:rows, 2, replace= T)
c.indices <- sample(1:cols, 2, replace= T)
n <- sum(ctable)

n.r1 <- as.numeric(rowsums[r.indices[1]])
n.c1 <- as.numeric(colsums[c.indices[1]])

n.r2 <- as.numeric(rowsums[r.indices[2]])
n.c2 <- as.numeric(colsums[c.indices[2]])

expected1 <- (n.r1*n.c1)/n 
expected2 <- (n.r2*n.c2)/n

#Final expected counts for the two points
expected1
expected2
```

### d. Proceed to apply your _my.chisq.test()_ and interpret the results. As a sanity check, also run _R_'s built-in _chisq.test()_ function on that same data, make sure the outputted $\chi^2$ and $p$-values match with those provided by _my.chisq.test()_. 

```{r}
my.chisq.test(ctable)

chisq.test(ctable)
```

My test works everywhere except for computing the p-value, where it seems to fail. However, when I test my function on another dummy table , it seems to work just fine. What could be the issue?

```{r}
my.chisq.test(data)
chisq.test(data)
```


### e. In case you end up claiming that variables are not independent, proceed to make a few comments on strength of the relationship (as was done for Income & Happiness example in class).

Since we have a low p-value, we can confirm that we have statistically significant evidence of assocation. We cannot say anything about the practical strength of that association without using either the difference of proportions or ratio of proportions.

```{r}
# Return to later.
```

# Problem #2 (I will not complete this part, as I never wrote Problem #1 for HW 11. However, I will use the two-sample proportion $z$-test that's built into R.)

Subjects were randomly assigned to regularly take aspirin or placebo, and followed up with over a 5-year period on whether they suffered a cancer death.

Main question: Is there a difference in cancer death rates between aspirin & placebo groups?

    a. Use your two-sample proportion $z$-test function from Problem #1 HW 11 (previous semester) to conduct appropriate hypothesis test to address the main question. What are the parameters of interest? What are the hypotheses? What's the conclusion?
    
    b. Use $\chi^2$-test to address the main question. Formulate the hypotheses. What's the conclusion?
    
    c. Are your $p$-values in parts (a) and (b) equal? there should be direct correspondence between $\chi^2$ test of independence for $2 \times 2$ tables, and two-sided proportion test, in big part due to the fact that
    
$$z^2 \equiv X^2$$

and that 

$$Z^2 \equiv \chi^2_1, Z \sim N(0,1).$$


# Problem 3

From **Agresti** book, do exercises:

## 11.84 Degrees of freedom explained
  For testing independence in a contingency table of size $r \times c$, the degrees of freedom ($df$) for the chi-squared distribution equal $df = (r-1) \times (c-1)$. They have the following interpretation: Given the row and column marginal totals in an $r \times c$ contingency table, the cell counts in a rectangular block of size $(r-1) \times (c-1)$ determine all the other cell counts. Consider the following table, which cross-classifies political views by whether the subject would ever vote for a female president, based on the 2010 GSS. For this $3 \times 2$ table, suppose we know the counts in the upper left-hand $(3-1) \times (2-1) = 2 \times 1$ block of the table, as shown.
  
```{r}
femprez <- matrix(c(56, NA, 58, 490, NA, 509, NA, NA, 61, 604, 24, 628), ncol = 3, byrow = TRUE)
colnames(femprez) <- c("Yes", "No", "Total")
rownames(femprez) <- c("Extremely Liberal", "Moderate", "Extremely Conservative", "Total")

femprez <- as.table(femprez)

femprez
```

### a. Given the cell counts and the row and column totals, fill in the counts that must appear in the blank cells.

```{r}
femprez.fill <- matrix(c(56,(58-56), 58, 490, (509-490), 509, (61 -(24 - ((58-56)+(509-490)) )), (24 - ((58-56)+(509-490))), 61, 604, 24, 628), ncol = 3, byrow = TRUE)
colnames(femprez.fill) <- c("Yes", "No", "Total")
rownames(femprez.fill) <- c("Extremely Liberal", "Moderate", "Extremely Conservative", "Total")

femprez.fill <- as.table(femprez.fill)

femprez.fill
```

### b. Now, suppose instead of the preceding table, you are shown the following table, this time only revealing a $2 \times 1$ block in the lower-right part. Find the counts in the remaining cells.

```{r}
femprez2 <- matrix(c(NA, NA, 58, NA, 19, 509, NA, 3, 61, 604, 24, 628), ncol = 3, byrow = TRUE)
colnames(femprez2) <- c("Yes", "No", "Total")
rownames(femprez2) <- c("Extremely Liberal", "Moderate", "Extremely Conservative", "Total")

femprez2 <- as.table(femprez2)

femprez2
```

Solution:

```{r}
femprez2.fill <- matrix(c(604-((509-19)+(61-3)), 58-(604-((509-19)+(61-3))), 58, (509-19), 19, 509, (61-3), 3, 61, 604, 24, 628), ncol = 3, byrow = TRUE)
colnames(femprez2.fill) <- c("Yes", "No", "Total")
rownames(femprez2.fill) <- c("Extremely Liberal", "Moderate", "Extremely Conservative", "Total")

femprez2.fill <- as.table(femprez2.fill)

femprez2.fill
```

## 11.9  Happiness and gender (and calculate all the expected cell counts, for practice)

For the $2 \times 3$ table on gender and happiness in Exercise 11.4 (shown below), software tells us that $\chi^2 = 1.04$ and the P-value = 0.59.

```{r}
happy.gender <-matrix(c(154, 592, 336, 123, 502, 257), ncol = 3, byrow =TRUE)
colnames(happy.gender) <- c("Not", "Pretty", "Very")
rownames(happy.gender) <- c("Female", "Male")
happy.gender <- as.table(happy.gender)

happy.gender

```

### a. State the null and alternative hypothesis, in context, to which these results apply.

- $H_0 :=$ Happiness is independent of gender.

- $H_a :=$ Happiness is dependent on gender.
  
### b. Interpret the $p$-value.

There is insufficient evidence to reject the null hypothesis.





